{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExoNAMD API v1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The observer wants to compute the relative and/or absolute NAMD of:\n",
    "\n",
    "- a given multiplanetary system;\n",
    "- a subset of multiplanetary systems;\n",
    "- all the known ones.\n",
    "\n",
    "This tool handles all of the above cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "\n",
    "from exonamd.utils import ROOT\n",
    "from exonamd.utils import fetch_aliases\n",
    "from exonamd.utils import update_host\n",
    "from exonamd.utils import update_planet\n",
    "from exonamd.solve import solve_values\n",
    "from exonamd.interp import interp_eccentricity\n",
    "from exonamd.interp import interp_mass\n",
    "from exonamd.interp import interp_inclination\n",
    "from exonamd.interp import interp_sma\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_columns = 20\n",
    "pd.options.display.max_rows = 30\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: getting the data\n",
    "\n",
    "This task retrieves the parameters of confirmed systems from the NASA Exoplanet Archive database, and stores them in a local database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL for the API\n",
    "url = \"https://exoplanetarchive.ipac.caltech.edu/TAP/sync\"\n",
    "\n",
    "# Define the date you want to filter by\n",
    "from_scratch = False  # change to False in production\n",
    "if from_scratch:\n",
    "    latest = datetime.strptime(\"1990-01-01\", \"%Y-%m-%d\")  # Example date\n",
    "else:\n",
    "    # df_old = pd.read_csv(os.path.join(ROOT, \"data\", \"exo.csv\"))\n",
    "    df_old = pd.read_csv(os.path.join(\"../exonamd/\", \"data\", \"exo.csv\"))\n",
    "    latest = df_old[\"rowupdate\"].max()\n",
    "    latest = datetime.strptime(latest, \"%Y-%m-%d\")  # Example date\n",
    "    latest = latest - timedelta(days=1)\n",
    "\n",
    "# Convert the date to a string in the format 'YYYY-MM-DD'\n",
    "latest = latest.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Define the multiplicity you want to filter by\n",
    "multiplicity = 1\n",
    "\n",
    "# Define the SQL query to retrieve the required data\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    hostname, \n",
    "    pl_name, \n",
    "    default_flag,\n",
    "    rowupdate,\n",
    "    sy_pnum, \n",
    "    st_rad,\n",
    "    st_mass,\n",
    "    pl_orbper,\n",
    "    pl_orbsmax, \n",
    "    pl_orbsmaxerr1, \n",
    "    pl_orbsmaxerr2, \n",
    "    pl_rade,\n",
    "    pl_radeerr1,\n",
    "    pl_radeerr2,\n",
    "    pl_bmasse, \n",
    "    pl_bmasseerr1, \n",
    "    pl_bmasseerr2, \n",
    "    pl_orbeccen, \n",
    "    pl_orbeccenerr1, \n",
    "    pl_orbeccenerr2, \n",
    "    pl_orbincl, \n",
    "    pl_orbinclerr1, \n",
    "    pl_orbinclerr2,\n",
    "    pl_trueobliq,\n",
    "    pl_trueobliqerr1,\n",
    "    pl_trueobliqerr2,\n",
    "    pl_ratdor,\n",
    "    pl_ratror\n",
    "FROM ps\n",
    "WHERE\n",
    "    sy_pnum > '{multiplicity}'\n",
    "    AND rowupdate > '{latest}'\n",
    "\"\"\"\n",
    "\n",
    "# Define the parameters for the request\n",
    "params = {\n",
    "    \"query\": query,\n",
    "    \"format\": \"json\",\n",
    "}\n",
    "\n",
    "# Make the request to the API\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON response\n",
    "    data = response.json()\n",
    "    # Convert the JSON data to a pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with None values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({None: np.nan, \"\": np.nan})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: dealing with the aliases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch aliases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 3/3 entries on try 1\n"
     ]
    }
   ],
   "source": [
    "aliases = fetch_aliases(df[\"hostname\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curate aliases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"hostname\"] = df.apply(update_host, args=(aliases,), axis=1)\n",
    "df[\"pl_name\"] = df.apply(update_planet, args=(aliases,), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check that the names are consistent\n",
    "\n",
    "for hostname in df[\"hostname\"].unique():\n",
    "    df_host = df[df[\"hostname\"] == hostname]\n",
    "    names = df_host[\"pl_name\"]\n",
    "    if len(set([name[:3] for name in names])) > 1:\n",
    "        print(f\"Inconsistent name for {hostname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: computing missing values (if any) from simple equations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    [\n",
    "        \"pl_orbsmax\",\n",
    "        \"pl_ratdor\",\n",
    "        \"st_rad\",\n",
    "        \"pl_rade\",\n",
    "        \"pl_ratror\",\n",
    "        \"pl_orbper\",\n",
    "        \"st_mass\",\n",
    "    ]\n",
    "] = df.apply(solve_values, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: storing the curated database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not from_scratch:\n",
    "    df_new = df.copy()\n",
    "    df = pd.concat([df_new, df_old], ignore_index=True)\n",
    "    df = df.drop_duplicates(keep=\"last\")\n",
    "\n",
    "df.to_csv(os.path.join(\"../exonamd/\", \"data\", \"exo.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(os.path.join(\"../exonamd/\", \"data\", \"exo.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns that are no longer needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\n",
    "    columns=[\n",
    "        \"pl_ratdor\",\n",
    "        \"st_rad\",\n",
    "        \"pl_ratror\",\n",
    "        \"pl_orbper\",\n",
    "        \"st_mass\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: input missing values (if any) by interpolation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use nanmedian to thin down the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_indices = []\n",
    "\n",
    "for planet in df[\"pl_name\"].unique():\n",
    "    df_planet = df[df[\"pl_name\"] == planet]\n",
    "    default_index = df_planet[df_planet[\"default_flag\"] == 1].index\n",
    "    for col in [\n",
    "        c\n",
    "        for c in df_planet.columns\n",
    "        if c not in [\"hostname\", \"pl_name\", \"default_flag\", \"rowupdate\"]\n",
    "    ]:\n",
    "        avg = np.nanmedian(df_planet[col].values)\n",
    "        df.loc[default_index, col] = avg\n",
    "    keep_indices.extend(default_index)\n",
    "\n",
    "df.drop(df.index[~df.index.isin(keep_indices)], inplace=True)\n",
    "df.drop(columns=\"default_flag\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate flags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"flag\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve missing eccentricity values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    [\n",
    "        \"pl_orbeccen\",\n",
    "        \"pl_orbeccenerr1\",\n",
    "        \"pl_orbeccenerr2\",\n",
    "        \"flag\",\n",
    "    ]\n",
    "] = df.apply(interp_eccentricity, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve missing planetary mass values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    [\n",
    "        \"pl_bmasse\",\n",
    "        \"pl_bmasseerr1\",\n",
    "        \"pl_bmasseerr2\",\n",
    "        \"flag\",\n",
    "    ]\n",
    "] = df.apply(interp_mass, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns that are no longer needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"pl_rade\", \"pl_radeerr1\", \"pl_radeerr2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove systems where at least one planet has no mass or semi-major axis (if any)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_indices = []\n",
    "for hostname in df[\"hostname\"].unique():\n",
    "    df_host = df[df[\"hostname\"] == hostname]\n",
    "    if df_host[[\"pl_bmasse\", \"pl_orbsmax\"]].isnull().any().any():\n",
    "        # print(\n",
    "        #     f\"Removing {hostname} \"\n",
    "        #     \"due to no mass or semi-major axis.\"\n",
    "        # )\n",
    "        remove_indices.extend(df_host.index)\n",
    "df.drop(df.index[df.index.isin(remove_indices)], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve missing values in inclinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    [\n",
    "        \"pl_orbincl\",\n",
    "        \"pl_orbinclerr1\",\n",
    "        \"pl_orbinclerr2\",\n",
    "        \"flag\",\n",
    "    ]\n",
    "] = df.apply(interp_inclination, args=(df,), axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve missing values in semi-major axis uncertainties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    [\n",
    "        \"pl_orbsmaxerr1\",\n",
    "        \"pl_orbsmaxerr2\",\n",
    "        \"flag\",\n",
    "    ]\n",
    "] = df.apply(interp_sma, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: storing the curated+interpolated database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(\"../exonamd/\", \"data\", \"exo_interp.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exonamd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
