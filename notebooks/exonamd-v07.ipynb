{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExoNAMD API v1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The observer wants to compute the relative and/or absolute NAMD of:\n",
    "- a given multiplanetary system;\n",
    "- a subset of multiplanetary systems;\n",
    "- or all the known ones.\n",
    "\n",
    "This tool handles all of the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "pd.options.display.max_columns = 20\n",
    "pd.options.display.max_rows = 30\n",
    "pd.options.mode.copy_on_write = True\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from exonamd.utils import ROOT\n",
    "from exonamd.utils import fetch_aliases\n",
    "from exonamd.utils import update_host\n",
    "from exonamd.utils import update_planet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: getting the data\n",
    "\n",
    "This task retrieves the parameters of confirmed systems from the NASA Exoplanet Archive database, and stores them in a local database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL for the API\n",
    "url = \"https://exoplanetarchive.ipac.caltech.edu/TAP/sync\"\n",
    "\n",
    "# Define the date you want to filter by\n",
    "from_scratch = True  # change to False in production\n",
    "if from_scratch:\n",
    "    latest = datetime.strptime(\"1990-01-01\", \"%Y-%m-%d\")  # Example date\n",
    "else:\n",
    "    df_old = pd.read_csv(os.path.join(ROOT, \"data\", \"exo.csv\"))\n",
    "    latest = df_old[\"rowupdate\"].max()\n",
    "    latest = datetime.strptime(latest, \"%Y-%m-%d\")  # Example date\n",
    "    latest = latest - timedelta(days=1)\n",
    "\n",
    "# Convert the date to a string in the format 'YYYY-MM-DD'\n",
    "latest = latest.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Define the multiplicity you want to filter by\n",
    "multiplicity = 5\n",
    "\n",
    "# Define the SQL query to retrieve the required data\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    hostname, \n",
    "    pl_name, \n",
    "    default_flag,\n",
    "    rowupdate,\n",
    "    sy_pnum, \n",
    "    st_rad,\n",
    "    st_raderr1,\n",
    "    st_raderr2,\n",
    "    st_mass,\n",
    "    st_masserr1,\n",
    "    st_masserr2,\n",
    "    pl_orbper,\n",
    "    pl_orbpererr1,\n",
    "    pl_orbpererr2,\n",
    "    pl_orbsmax, \n",
    "    pl_orbsmaxerr1, \n",
    "    pl_orbsmaxerr2, \n",
    "    pl_rade,\n",
    "    pl_radeerr1,\n",
    "    pl_radeerr2,\n",
    "    pl_bmasse, \n",
    "    pl_bmasseerr1, \n",
    "    pl_bmasseerr2, \n",
    "    pl_orbeccen, \n",
    "    pl_orbeccenerr1, \n",
    "    pl_orbeccenerr2, \n",
    "    pl_orbincl, \n",
    "    pl_orbinclerr1, \n",
    "    pl_orbinclerr2,\n",
    "    pl_trueobliq,\n",
    "    pl_trueobliqerr1,\n",
    "    pl_trueobliqerr2,\n",
    "    pl_ratdor,\n",
    "    pl_ratdorerr1,\n",
    "    pl_ratdorerr2,\n",
    "    pl_ratror,\n",
    "    pl_ratrorerr1,\n",
    "    pl_ratrorerr2\n",
    "FROM ps\n",
    "WHERE\n",
    "    sy_pnum > '{multiplicity}'\n",
    "    AND rowupdate > '{latest}'\n",
    "\"\"\"\n",
    "\n",
    "# Define the parameters for the request\n",
    "params = {\n",
    "    \"query\": query,\n",
    "    \"format\": \"json\",\n",
    "}\n",
    "\n",
    "# Make the request to the API\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON response\n",
    "    data = response.json()\n",
    "    # Convert the JSON data to a pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: dealing with the aliases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 13/13 entries on try 1\n"
     ]
    }
   ],
   "source": [
    "aliases = fetch_aliases(df[\"hostname\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curate aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For testing\n",
    "# df2 = df.copy()\n",
    "# df2.loc[df2['hostname'] == 'Kepler-20', 'hostname'] = 'KOI-70'\n",
    "# df2.loc[df2['hostname'] == 'Kepler-80', 'hostname'] = 'KIC 4852528'\n",
    "# df2['hostname'] = df2.apply(update_host, args=(aliases, True), axis=1)\n",
    "df[\"hostname\"] = df.apply(update_host, args=(aliases, False), axis=1)\n",
    "\n",
    "# # For testing\n",
    "# df2 = df.copy()\n",
    "# df2.loc[df2['pl_name'] == 'Kepler-20 c', 'pl_name'] = 'KOI-70.01'\n",
    "# df2.loc[df2['pl_name'] == 'Kepler-11 b', 'pl_name'] = 'KOI-157 b'\n",
    "# df2['pl_name'] = df2.apply(update_planet, args=(aliases, True), axis=1)\n",
    "df[\"pl_name\"] = df.apply(update_planet, args=(aliases, False), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check that the names are consistent\n",
    "\n",
    "for hostname in df[\"hostname\"].unique():\n",
    "    df_host = df[df[\"hostname\"] == hostname]\n",
    "    names = df_host[\"pl_name\"]\n",
    "    if len(set([name[:3] for name in names])) > 1:\n",
    "        print(f\"Inconsistent name for {hostname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(ROOT, \"data\", \"task2.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: computing missing values (if any) from simple equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exonamd.utils import solve_a_rs\n",
    "from exonamd.utils import solve_rprs\n",
    "from exonamd.utils import solve_a_period\n",
    "\n",
    "\n",
    "def complete_values(row):\n",
    "\n",
    "    sma = row[\"pl_orbsmax\"]\n",
    "    ars = row[\"pl_ratdor\"]\n",
    "    rstar = row[\"st_rad\"]\n",
    "    rplanet = row[\"pl_rade\"]\n",
    "    rprs = row[\"pl_ratror\"]\n",
    "    period = row[\"pl_orbper\"]\n",
    "    mstar = row[\"st_mass\"]\n",
    "\n",
    "    # Rank groups\n",
    "    a_rs_ = np.isnan(sma) + np.isnan(ars) + np.isnan(rstar)\n",
    "    rprs_ = np.isnan(rplanet) + np.isnan(rprs) + np.isnan(rstar)\n",
    "    a_period_ = np.isnan(period) + np.isnan(sma) + np.isnan(mstar)\n",
    "    solve_order = np.argsort([a_rs_, rprs_, a_period_])\n",
    "    for i in solve_order:\n",
    "        if i == 0:\n",
    "            # Solve semi-major axis -- stellar radius system of equations.\n",
    "            solution = solve_a_rs(sma, rstar, ars)\n",
    "            sma, rstar, ars = solution\n",
    "        elif i == 1:\n",
    "            # Solve planet radius -- stellar radius system of equations.\n",
    "            solution = solve_rprs(rplanet, rstar, rprs)\n",
    "            rplanet, rstar, rprs = solution\n",
    "        elif i == 2:\n",
    "            # Solve period-sma-mstar system of equations.\n",
    "            solution = solve_a_period(period, sma, mstar)\n",
    "            period, sma, mstar = solution\n",
    "\n",
    "    return sma, ars, rstar, rplanet, rprs, period, mstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    [\n",
    "        \"pl_orbsmax\",\n",
    "        \"pl_ratdor\",\n",
    "        \"st_rad\",\n",
    "        \"pl_rade\",\n",
    "        \"pl_ratror\",\n",
    "        \"pl_orbper\",\n",
    "        \"st_mass\",\n",
    "    ]\n",
    "] = df.apply(complete_values, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: storing the curated database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not from_scratch:\n",
    "    df_new = df.copy()\n",
    "    df = pd.concat([df_new, df_old], ignore_index=True)\n",
    "    df = df.drop_duplicates(keep=\"last\")\n",
    "\n",
    "df.to_csv(os.path.join(ROOT, \"data\", \"exo.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df[\"pl_trueobliq\"].notnull()][\n",
    "#     [\"pl_name\", \"pl_trueobliq\", \"pl_trueobliqerr1\", \"pl_trueobliqerr2\"]\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: input missing values (if any) by interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: storing the curated+interpolated database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exonamd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
